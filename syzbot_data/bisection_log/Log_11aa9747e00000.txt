bisecting cause commit starting from 7be97138e7276c71cc9ad1752dcb502d28f4400d
building syzkaller on a34e2c332411388ed2b3f6f1a3acdc062feceb79
testing commit 7be97138e7276c71cc9ad1752dcb502d28f4400d with gcc (GCC) 8.1.0
kernel signature: 377578ad4051f2ae397028a2928dca485fc53c496fcf7ae468a80a9ea392a15e
all runs: crashed: possible deadlock in send_sigurg
testing release v5.6
testing commit 7111951b8d4973bda27ff663f2cf18b663d15b48 with gcc (GCC) 8.1.0
kernel signature: 79700b1a903755f5b9358889bc743981d525bfdc8120f93c78e64e823729ff9a
all runs: OK
# git bisect start 7be97138e7276c71cc9ad1752dcb502d28f4400d 7111951b8d4973bda27ff663f2cf18b663d15b48
Bisecting: 4567 revisions left to test after this (roughly 12 steps)
[56a451b780676bc1cdac011735fe2869fa2e9abf] Merge tag 'ntb-5.7' of git://github.com/jonmason/ntb
testing commit 56a451b780676bc1cdac011735fe2869fa2e9abf with gcc (GCC) 8.1.0
kernel signature: 83b5251a771ec6cb78ba6bf170b6d0ac608ea02ee0644c0fd849139f240db7b9
all runs: OK
# git bisect good 56a451b780676bc1cdac011735fe2869fa2e9abf
Bisecting: 2270 revisions left to test after this (roughly 11 steps)
[ed52f2c608c9451fa2bad298b2ab927416105d65] Merge git://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next
testing commit ed52f2c608c9451fa2bad298b2ab927416105d65 with gcc (GCC) 8.1.0
kernel signature: 13b5031d5d934cdf056acfaf8607e64a724ef3704b13b154d539cf69f522f4db
all runs: OK
# git bisect good ed52f2c608c9451fa2bad298b2ab927416105d65
Bisecting: 1125 revisions left to test after this (roughly 10 steps)
[69ddce0970d9d1de63bed9c24eefa0814db29a5a] Merge tag 'amd-drm-next-5.7-2020-03-10' of git://people.freedesktop.org/~agd5f/linux into drm-next
testing commit 69ddce0970d9d1de63bed9c24eefa0814db29a5a with gcc (GCC) 8.1.0
kernel signature: 32373261fb366be95952dbe2c13050e20d10b8747b56ca1892c776498cda472d
all runs: OK
# git bisect good 69ddce0970d9d1de63bed9c24eefa0814db29a5a
Bisecting: 456 revisions left to test after this (roughly 9 steps)
[f365ab31efacb70bed1e821f7435626e0b2528a6] Merge tag 'drm-next-2020-04-01' of git://anongit.freedesktop.org/drm/drm
testing commit f365ab31efacb70bed1e821f7435626e0b2528a6 with gcc (GCC) 8.1.0
kernel signature: ac9f4373ad1051b4e49651fc1e63e65a9e1355be618d7805afe0219e6fccda78
all runs: OK
# git bisect good f365ab31efacb70bed1e821f7435626e0b2528a6
Bisecting: 212 revisions left to test after this (roughly 8 steps)
[919dce24701f7b34681a6a1d3ef95c9f6c4fb1cc] Merge tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/rdma/rdma
testing commit 919dce24701f7b34681a6a1d3ef95c9f6c4fb1cc with gcc (GCC) 8.1.0
kernel signature: 3f6c72506ed4a2f2686c41b46b26ff4d7f6f36f8a1c2f8c4239a04af01e05b67
all runs: OK
# git bisect good 919dce24701f7b34681a6a1d3ef95c9f6c4fb1cc
Bisecting: 106 revisions left to test after this (roughly 7 steps)
[d59f44d3e723c4f7143d910dfa333f2bdb587bbc] xfs: directory bestfree check should release buffers
testing commit d59f44d3e723c4f7143d910dfa333f2bdb587bbc with gcc (GCC) 8.1.0
kernel signature: ded3a6cca06d7acd6f5e6fd38396037d1fedf511bdcf9a520739c4b41f5b4e3d
all runs: OK
# git bisect good d59f44d3e723c4f7143d910dfa333f2bdb587bbc
Bisecting: 53 revisions left to test after this (roughly 6 steps)
[7ef482fa65513b18eed05a5c5f00413aad137810] helper for mount rootwards traversal
testing commit 7ef482fa65513b18eed05a5c5f00413aad137810 with gcc (GCC) 8.1.0
kernel signature: bf6ace0708b063fc74ca58166691ce17fd4682281526891e1d84e0da762dc7c8
all runs: OK
# git bisect good 7ef482fa65513b18eed05a5c5f00413aad137810
Bisecting: 26 revisions left to test after this (roughly 5 steps)
[4b871ce26ab2c758ea90b8dd659e4267aae9e943] Merged 'Infrastructure to allow fixing exec deadlocks' from Bernd Edlinger
testing commit 4b871ce26ab2c758ea90b8dd659e4267aae9e943 with gcc (GCC) 8.1.0
kernel signature: cc4e07e4019ba9f7c6a525a2bc50234522ae80605731d52a2c726e578eae7927
all runs: crashed: possible deadlock in send_sigurg
# git bisect bad 4b871ce26ab2c758ea90b8dd659e4267aae9e943
Bisecting: 13 revisions left to test after this (roughly 4 steps)
[2ca7be7d55ad84fb0f7c2a23fb700a28fd76b19a] exec: Only compute current once in flush_old_exec
testing commit 2ca7be7d55ad84fb0f7c2a23fb700a28fd76b19a with gcc (GCC) 8.1.0
kernel signature: 3970c144ab59df3b51b90ab4f640ed5edba417049762fbb1d184ed0ca6f0c935
all runs: crashed: possible deadlock in send_sigurg
# git bisect bad 2ca7be7d55ad84fb0f7c2a23fb700a28fd76b19a
Bisecting: 6 revisions left to test after this (roughly 3 steps)
[7bc3e6e55acf065500a24621f3b313e7e5998acf] proc: Use a list of inodes to flush from proc
testing commit 7bc3e6e55acf065500a24621f3b313e7e5998acf with gcc (GCC) 8.1.0
kernel signature: 7e53133fc4ee888ed2f05b4ef8adbf641a4cfed59e05e142893b4d35544ca45c
all runs: crashed: possible deadlock in send_sigurg
# git bisect bad 7bc3e6e55acf065500a24621f3b313e7e5998acf
Bisecting: 2 revisions left to test after this (roughly 2 steps)
[080f6276fccfb3923691e57c1b44a627eabd1a25] proc: In proc_prune_siblings_dcache cache an aquired super block
testing commit 080f6276fccfb3923691e57c1b44a627eabd1a25 with gcc (GCC) 8.1.0
kernel signature: 9fd17bc12ac55ff172d10b1b70a08abed0f0aae8231abb149b23824a33309bdc
all runs: OK
# git bisect good 080f6276fccfb3923691e57c1b44a627eabd1a25
Bisecting: 0 revisions left to test after this (roughly 1 step)
[71448011ea2a1cd36d8f5cbdab0ed716c454d565] proc: Clear the pieces of proc_inode that proc_evict_inode cares about
testing commit 71448011ea2a1cd36d8f5cbdab0ed716c454d565 with gcc (GCC) 8.1.0
kernel signature: 3a5305989d05423223bb3948add91ccd0e73f57c945f3a078270dec726e8a607
all runs: OK
# git bisect good 71448011ea2a1cd36d8f5cbdab0ed716c454d565
7bc3e6e55acf065500a24621f3b313e7e5998acf is the first bad commit
commit 7bc3e6e55acf065500a24621f3b313e7e5998acf
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Feb 19 18:22:26 2020 -0600

    proc: Use a list of inodes to flush from proc
    
    Rework the flushing of proc to use a list of directory inodes that
    need to be flushed.
    
    The list is kept on struct pid not on struct task_struct, as there is
    a fixed connection between proc inodes and pids but at least for the
    case of de_thread the pid of a task_struct changes.
    
    This removes the dependency on proc_mnt which allows for different
    mounts of proc having different mount options even in the same pid
    namespace and this allows for the removal of proc_mnt which will
    trivially the first mount of proc to honor it's mount options.
    
    This flushing remains an optimization.  The functions
    pid_delete_dentry and pid_revalidate ensure that ordinary dcache
    management will not attempt to use dentries past the point their
    respective task has died.  When unused the shrinker will
    eventually be able to remove these dentries.
    
    There is a case in de_thread where proc_flush_pid can be
    called early for a given pid.  Which winds up being
    safe (if suboptimal) as this is just an optiimization.
    
    Only pid directories are put on the list as the other
    per pid files are children of those directories and
    d_invalidate on the directory will get them as well.
    
    So that the pid can be used during flushing it's reference count is
    taken in release_task and dropped in proc_flush_pid.  Further the call
    of proc_flush_pid is moved after the tasklist_lock is released in
    release_task so that it is certain that the pid has already been
    unhashed when flushing it taking place.  This removes a small race
    where a dentry could recreated.
    
    As struct pid is supposed to be small and I need a per pid lock
    I reuse the only lock that currently exists in struct pid the
    the wait_pidfd.lock.
    
    The net result is that this adds all of this functionality
    with just a little extra list management overhead and
    a single extra pointer in struct pid.
    
    v2: Initialize pid->inodes.  I somehow failed to get that
        initialization into the initial version of the patch.  A boot
        failure was reported by "kernel test robot <lkp@intel.com>", and
        failure to initialize that pid->inodes matches all of the reported
        symptoms.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

 fs/proc/base.c          | 111 ++++++++++++++++--------------------------------
 fs/proc/inode.c         |   2 +-
 fs/proc/internal.h      |   1 +
 include/linux/pid.h     |   1 +
 include/linux/proc_fs.h |   4 +-
 kernel/exit.c           |   4 +-
 kernel/pid.c            |   1 +
 7 files changed, 45 insertions(+), 79 deletions(-)
culprit signature: 7e53133fc4ee888ed2f05b4ef8adbf641a4cfed59e05e142893b4d35544ca45c
parent  signature: 3a5305989d05423223bb3948add91ccd0e73f57c945f3a078270dec726e8a607
revisions tested: 14, total time: 3h23m6.78938174s (build: 1h28m36.666444931s, test: 1h53m19.915402984s)
first bad commit: 7bc3e6e55acf065500a24621f3b313e7e5998acf proc: Use a list of inodes to flush from proc
cc: ["adobriyan@gmail.com" "akpm@linux-foundation.org" "allison@lohutok.net" "areber@redhat.com" "aubrey.li@linux.intel.com" "avagin@gmail.com" "christian@brauner.io" "cyphar@cyphar.com" "ebiederm@xmission.com" "gregkh@linuxfoundation.org" "guro@fb.com" "joel@joelfernandes.org" "keescook@chromium.org" "linmiaohe@huawei.com" "linux-fsdevel@vger.kernel.org" "linux-kernel@vger.kernel.org" "mhocko@suse.com" "mingo@kernel.org" "oleg@redhat.com" "peterz@infradead.org" "sargun@sargun.me" "tglx@linutronix.de" "viro@zeniv.linux.org.uk"]
crash: possible deadlock in send_sigurg
========================================================
WARNING: possible irq lock inversion dependency detected
5.6.0-rc2-syzkaller #0 Not tainted
--------------------------------------------------------
ksoftirqd/0/9 just changed the state of lock:
ffffffff88a090d8 (tasklist_lock){.+.?}, at: send_sigurg+0x8a/0x260 fs/fcntl.c:838
but this lock took another, SOFTIRQ-unsafe lock in the past:
 (&pid->wait_pidfd){+.+.}


and interrupts could create inverse lock ordering between them.


other info that might help us debug this:
 Possible interrupt unsafe locking scenario:

       CPU0                    CPU1
       ----                    ----
  lock(&pid->wait_pidfd);
                               local_irq_disable();
                               lock(tasklist_lock);
                               lock(&pid->wait_pidfd);
  <Interrupt>
    lock(tasklist_lock);

 *** DEADLOCK ***

4 locks held by ksoftirqd/0/9:
 #0: ffffffff88ba5600 (rcu_read_lock){....}, at: __write_once_size include/linux/compiler.h:226 [inline]
 #0: ffffffff88ba5600 (rcu_read_lock){....}, at: __skb_unlink include/linux/skbuff.h:2046 [inline]
 #0: ffffffff88ba5600 (rcu_read_lock){....}, at: __skb_dequeue include/linux/skbuff.h:2061 [inline]
 #0: ffffffff88ba5600 (rcu_read_lock){....}, at: process_backlog+0x1ab/0x710 net/core/dev.c:6142
 #1: ffffffff88ba5600 (rcu_read_lock){....}, at: __skb_pull include/linux/skbuff.h:2277 [inline]
 #1: ffffffff88ba5600 (rcu_read_lock){....}, at: ip_local_deliver_finish+0x11b/0x2f0 net/ipv4/ip_input.c:228
 #2: ffff888099820d60 (slock-AF_INET/1){+.-.}, at: tcp_v4_rcv+0x25e3/0x34c0 net/ipv4/tcp_ipv4.c:1995
 #3: ffff8880a05f2e60 (&f->f_owner.lock){.+.?}, at: send_sigurg+0x19/0x260 fs/fcntl.c:822

the shortest dependencies between 2nd lock and 1st lock:
 -> (&pid->wait_pidfd){+.+.} {
    HARDIRQ-ON-W at:
                      lock_acquire+0x19b/0x420 kernel/locking/lockdep.c:4484
                      __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
                      _raw_spin_lock+0x2a/0x40 kernel/locking/spinlock.c:151
                      spin_lock include/linux/spinlock.h:338 [inline]
                      proc_pid_make_inode+0x1c0/0x390 fs/proc/base.c:1880
                      proc_pid_instantiate+0x40/0x140 fs/proc/base.c:3285
                      proc_pid_lookup+0x134/0x240 fs/proc/base.c:3320
                      proc_root_lookup+0x16/0x40 fs/proc/root.c:243
                      __lookup_slow+0x204/0x3d0 fs/namei.c:1757
                      lookup_slow fs/namei.c:1774 [inline]
                      walk_component+0x684/0xef0 fs/namei.c:1915
                      link_path_walk.part.40+0x3c4/0xdc0 fs/namei.c:2238
                      link_path_walk fs/namei.c:2172 [inline]
                      path_openat+0x194/0x2aa0 fs/namei.c:3606
                      do_filp_open+0x171/0x240 fs/namei.c:3637
                      do_sys_openat2+0x2b9/0x480 fs/open.c:1149
                      do_sys_open+0x85/0xd0 fs/open.c:1165
                      do_syscall_64+0xc6/0x5e0 arch/x86/entry/common.c:294
                      entry_SYSCALL_64_after_hwframe+0x49/0xbe
    SOFTIRQ-ON-W at:
                      lock_acquire+0x19b/0x420 kernel/locking/lockdep.c:4484
                      __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
                      _raw_spin_lock+0x2a/0x40 kernel/locking/spinlock.c:151
                      spin_lock include/linux/spinlock.h:338 [inline]
                      proc_pid_make_inode+0x1c0/0x390 fs/proc/base.c:1880
                      proc_pid_instantiate+0x40/0x140 fs/proc/base.c:3285
                      proc_pid_lookup+0x134/0x240 fs/proc/base.c:3320
                      proc_root_lookup+0x16/0x40 fs/proc/root.c:243
                      __lookup_slow+0x204/0x3d0 fs/namei.c:1757
                      lookup_slow fs/namei.c:1774 [inline]
                      walk_component+0x684/0xef0 fs/namei.c:1915
                      link_path_walk.part.40+0x3c4/0xdc0 fs/namei.c:2238
                      link_path_walk fs/namei.c:2172 [inline]
                      path_openat+0x194/0x2aa0 fs/namei.c:3606
                      do_filp_open+0x171/0x240 fs/namei.c:3637
                      do_sys_openat2+0x2b9/0x480 fs/open.c:1149
                      do_sys_open+0x85/0xd0 fs/open.c:1165
                      do_syscall_64+0xc6/0x5e0 arch/x86/entry/common.c:294
                      entry_SYSCALL_64_after_hwframe+0x49/0xbe
    INITIAL USE at:
                     lock_acquire+0x19b/0x420 kernel/locking/lockdep.c:4484
                     __raw_spin_lock_irqsave include/linux/spinlock_api_smp.h:110 [inline]
                     _raw_spin_lock_irqsave+0x95/0xc0 kernel/locking/spinlock.c:159
                     __wake_up_common_lock+0xa8/0x120 kernel/sched/wait.c:122
                     do_notify_pidfd kernel/signal.c:1895 [inline]
                     do_notify_parent+0x14c/0xbb0 kernel/signal.c:1922
                     exit_notify kernel/exit.c:668 [inline]
                     do_exit+0x206f/0x2a10 kernel/exit.c:824
                     call_usermodehelper_exec_async+0x47f/0x680 kernel/umh.c:125
                     ret_from_fork+0x24/0x30 arch/x86/entry/entry_64.S:352
  }
  ... key      at: [<ffffffff8abc66e0>] __key.53243+0x0/0x40
  ... acquired at:
   __raw_spin_lock_irqsave include/linux/spinlock_api_smp.h:110 [inline]
   _raw_spin_lock_irqsave+0x95/0xc0 kernel/locking/spinlock.c:159
   __wake_up_common_lock+0xa8/0x120 kernel/sched/wait.c:122
   do_notify_pidfd kernel/signal.c:1895 [inline]
   do_notify_parent+0x14c/0xbb0 kernel/signal.c:1922
   exit_notify kernel/exit.c:668 [inline]
   do_exit+0x206f/0x2a10 kernel/exit.c:824
   call_usermodehelper_exec_async+0x47f/0x680 kernel/umh.c:125
   ret_from_fork+0x24/0x30 arch/x86/entry/entry_64.S:352

-> (tasklist_lock){.+.?} {
   HARDIRQ-ON-R at:
                    lock_acquire+0x19b/0x420 kernel/locking/lockdep.c:4484
                    __raw_read_lock include/linux/rwlock_api_smp.h:149 [inline]
                    _raw_read_lock+0x2d/0x40 kernel/locking/spinlock.c:223
                    do_wait+0x364/0x840 kernel/exit.c:1444
                    kernel_wait4+0xdf/0x1b0 kernel/exit.c:1619
                    call_usermodehelper_exec_sync kernel/umh.c:150 [inline]
                    call_usermodehelper_exec_work+0x134/0x210 kernel/umh.c:187
                    process_one_work+0x903/0x15c0 kernel/workqueue.c:2264
                    worker_thread+0x82/0xb50 kernel/workqueue.c:2410
                    kthread+0x31d/0x3e0 kernel/kthread.c:255
                    ret_from_fork+0x24/0x30 arch/x86/entry/entry_64.S:352
   IN-SOFTIRQ-R at:
                    lock_acquire+0x19b/0x420 kernel/locking/lockdep.c:4484
                    __raw_read_lock include/linux/rwlock_api_smp.h:149 [inline]
                    _raw_read_lock+0x2d/0x40 kernel/locking/spinlock.c:223
                    send_sigurg+0x8a/0x260 fs/fcntl.c:838
                    sk_send_sigurg+0x6c/0x220 net/core/sock.c:2832
                    tcp_check_urg net/ipv4/tcp_input.c:5353 [inline]
                    tcp_urg+0x2ca/0xd80 net/ipv4/tcp_input.c:5394
                    tcp_rcv_established+0x9df/0x1f40 net/ipv4/tcp_input.c:5724
                    tcp_v4_do_rcv+0x517/0x790 net/ipv4/tcp_ipv4.c:1619
                    tcp_v4_rcv+0x2825/0x34c0 net/ipv4/tcp_ipv4.c:2001
                    ip_protocol_deliver_rcu+0x53/0x690 net/ipv4/ip_input.c:204
                    ip_local_deliver_finish+0x200/0x2f0 net/ipv4/ip_input.c:231
                    NF_HOOK include/linux/netfilter.h:307 [inline]
                    ip_local_deliver+0x2e5/0x3e0 net/ipv4/ip_input.c:252
                    NF_HOOK include/linux/netfilter.h:307 [inline]
                    ip_rcv+0xc9/0x2e0 net/ipv4/ip_input.c:538
                    __netif_receive_skb_one_core+0xe3/0x150 net/core/dev.c:5198
                    process_backlog+0x1f2/0x710 net/core/dev.c:6144
                    napi_poll net/core/dev.c:6582 [inline]
                    net_rx_action+0x415/0xd70 net/core/dev.c:6650
                    __do_softirq+0x26e/0x9b2 kernel/softirq.c:292
                    run_ksoftirqd+0x8f/0x100 kernel/softirq.c:603
                    smpboot_thread_fn+0x511/0x850 kernel/smpboot.c:165
                    kthread+0x31d/0x3e0 kernel/kthread.c:255
                    ret_from_fork+0x24/0x30 arch/x86/entry/entry_64.S:352
   SOFTIRQ-ON-R at:
                    lock_acquire+0x19b/0x420 kernel/locking/lockdep.c:4484
                    __raw_read_lock include/linux/rwlock_api_smp.h:149 [inline]
                    _raw_read_lock+0x2d/0x40 kernel/locking/spinlock.c:223
                    do_wait+0x364/0x840 kernel/exit.c:1444
                    kernel_wait4+0xdf/0x1b0 kernel/exit.c:1619
                    call_usermodehelper_exec_sync kernel/umh.c:150 [inline]
                    call_usermodehelper_exec_work+0x134/0x210 kernel/umh.c:187
                    process_one_work+0x903/0x15c0 kernel/workqueue.c:2264
                    worker_thread+0x82/0xb50 kernel/workqueue.c:2410
                    kthread+0x31d/0x3e0 kernel/kthread.c:255
                    ret_from_fork+0x24/0x30 arch/x86/entry/entry_64.S:352
   INITIAL USE at:
                   lock_acquire+0x19b/0x420 kernel/locking/lockdep.c:4484
                   __raw_write_lock_irq include/linux/rwlock_api_smp.h:196 [inline]
                   _raw_write_lock_irq+0x5e/0x80 kernel/locking/spinlock.c:311
                   copy_process+0x35da/0x6a50 kernel/fork.c:2203
                   _do_fork+0xf8/0xc00 kernel/fork.c:2430
                   kernel_thread+0x98/0xd0 kernel/fork.c:2517
                   rest_init+0x21/0x26e init/main.c:620
                   start_kernel+0x6c1/0x6ff init/main.c:992
                   secondary_startup_64+0xa4/0xb0 arch/x86/kernel/head_64.S:242
 }
 ... key      at: [<ffffffff88a090d8>] tasklist_lock+0x18/0x40
 ... acquired at:
   mark_lock_irq kernel/locking/lockdep.c:3316 [inline]
   mark_lock+0x501/0x11a0 kernel/locking/lockdep.c:3665
   mark_usage kernel/locking/lockdep.c:3557 [inline]
   __lock_acquire+0x145e/0x4370 kernel/locking/lockdep.c:3908
   lock_acquire+0x19b/0x420 kernel/locking/lockdep.c:4484
   __raw_read_lock include/linux/rwlock_api_smp.h:149 [inline]
   _raw_read_lock+0x2d/0x40 kernel/locking/spinlock.c:223
   send_sigurg+0x8a/0x260 fs/fcntl.c:838
   sk_send_sigurg+0x6c/0x220 net/core/sock.c:2832
   tcp_check_urg net/ipv4/tcp_input.c:5353 [inline]
   tcp_urg+0x2ca/0xd80 net/ipv4/tcp_input.c:5394
   tcp_rcv_established+0x9df/0x1f40 net/ipv4/tcp_input.c:5724
   tcp_v4_do_rcv+0x517/0x790 net/ipv4/tcp_ipv4.c:1619
   tcp_v4_rcv+0x2825/0x34c0 net/ipv4/tcp_ipv4.c:2001
   ip_protocol_deliver_rcu+0x53/0x690 net/ipv4/ip_input.c:204
   ip_local_deliver_finish+0x200/0x2f0 net/ipv4/ip_input.c:231
   NF_HOOK include/linux/netfilter.h:307 [inline]
   ip_local_deliver+0x2e5/0x3e0 net/ipv4/ip_input.c:252
   NF_HOOK include/linux/netfilter.h:307 [inline]
   ip_rcv+0xc9/0x2e0 net/ipv4/ip_input.c:538
   __netif_receive_skb_one_core+0xe3/0x150 net/core/dev.c:5198
   process_backlog+0x1f2/0x710 net/core/dev.c:6144
   napi_poll net/core/dev.c:6582 [inline]
   net_rx_action+0x415/0xd70 net/core/dev.c:6650
   __do_softirq+0x26e/0x9b2 kernel/softirq.c:292
   run_ksoftirqd+0x8f/0x100 kernel/softirq.c:603
   smpboot_thread_fn+0x511/0x850 kernel/smpboot.c:165
   kthread+0x31d/0x3e0 kernel/kthread.c:255
   ret_from_fork+0x24/0x30 arch/x86/entry/entry_64.S:352


stack backtrace:
CPU: 0 PID: 9 Comm: ksoftirqd/0 Not tainted 5.6.0-rc2-syzkaller #0
Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
Call Trace:
 __dump_stack lib/dump_stack.c:77 [inline]
 dump_stack+0x128/0x182 lib/dump_stack.c:118
 print_irq_inversion_bug kernel/locking/lockdep.c:3179 [inline]
 check_usage_forwards.cold.61+0x20/0x29 kernel/locking/lockdep.c:3203
 mark_lock_irq kernel/locking/lockdep.c:3316 [inline]
 mark_lock+0x501/0x11a0 kernel/locking/lockdep.c:3665
 mark_usage kernel/locking/lockdep.c:3557 [inline]
 __lock_acquire+0x145e/0x4370 kernel/locking/lockdep.c:3908
 lock_acquire+0x19b/0x420 kernel/locking/lockdep.c:4484
 __raw_read_lock include/linux/rwlock_api_smp.h:149 [inline]
 _raw_read_lock+0x2d/0x40 kernel/locking/spinlock.c:223
 send_sigurg+0x8a/0x260 fs/fcntl.c:838
 sk_send_sigurg+0x6c/0x220 net/core/sock.c:2832
 tcp_check_urg net/ipv4/tcp_input.c:5353 [inline]
 tcp_urg+0x2ca/0xd80 net/ipv4/tcp_input.c:5394
 tcp_rcv_established+0x9df/0x1f40 net/ipv4/tcp_input.c:5724
 tcp_v4_do_rcv+0x517/0x790 net/ipv4/tcp_ipv4.c:1619
 tcp_v4_rcv+0x2825/0x34c0 net/ipv4/tcp_ipv4.c:2001
 ip_protocol_deliver_rcu+0x53/0x690 net/ipv4/ip_input.c:204
 ip_local_deliver_finish+0x200/0x2f0 net/ipv4/ip_input.c:231
 NF_HOOK include/linux/netfilter.h:307 [inline]
 ip_local_deliver+0x2e5/0x3e0 net/ipv4/ip_input.c:252
 NF_HOOK include/linux/netfilter.h:307 [inline]
 ip_rcv+0xc9/0x2e0 net/ipv4/ip_input.c:538
 __netif_receive_skb_one_core+0xe3/0x150 net/core/dev.c:5198
 process_backlog+0x1f2/0x710 net/core/dev.c:6144
 napi_poll net/core/dev.c:6582 [inline]
 net_rx_action+0x415/0xd70 net/core/dev.c:6650
 __do_softirq+0x26e/0x9b2 kernel/softirq.c:292
 run_ksoftirqd+0x8f/0x100 kernel/softirq.c:603
 smpboot_thread_fn+0x511/0x850 kernel/smpboot.c:165
 kthread+0x31d/0x3e0 kernel/kthread.c:255
 ret_from_fork+0x24/0x30 arch/x86/entry/entry_64.S:352

